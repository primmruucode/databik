name: Notebook Deployment - Databricks
on:
  workflow_call:
    inputs:
      databricks_code_path:
        description: Databricks Service Path
        type: string
        required: true
      
      service_code_file:
        description: python code file path
        type: string
        required: true
env:
  DATABRICKS_HOST: https://8197127835171069.9.gcp.databricks.com
  DATABRICKS_TOKEN: dapi42fa2c27081b82922256499d58269033
    
  #secrets:
    #DATABRICKS_HOST_URL:
      #description:   'Databricks workspace URL'
      #required: true
    #DATABRICKS_TOKEN:
      #description: 'Access token for Databricks CLI'
      #required: true

jobs:
    push_to_dbs:
      runs-on: ubuntu-latest
    
      steps:
      - name: Checkout current repository
        uses: actions/checkout@v3.3.0
      
      - name: Set up python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
        
      - name: Databricks CLI config
        run: |
            pip install databricks-cli 
            cat > ~/.databrickscfg << EOF 
            [DEFAULT] 
            host = ${{ secrets.DATABRICKS_HOST_URL }} 
            token = ${{ secrets.DATABRICKS_TOKEN }} 
            jobs-api-version = 2.1 
            EOF 
    
      - name: Import code file to databricks workspace
        run: |
            databricks workspace import src/code/py.py ${{ inputs.databricks_code_path }} --language python --overwrite
     
      - name: Import config file to databricks workspace
        run: |
            databricks workspace import_dir etl/config /Users/user1/etl/config
     
      - name: Copy the libraries from github repo to DBFS
        run: |
            databricks fs cp etl-2.1-assembly.jar dbfs:/user1/etl/etl-2.1-assembly.jar
     
